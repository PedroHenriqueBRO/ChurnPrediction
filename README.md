# ğŸ¡ House Predictions - PrediÃ§Ã£o de Churn

Este projeto tem como objetivo **prever churn** (saÃ­da de clientes) a partir de dados histÃ³ricos, explorando diferentes modelos de Machine Learning e avaliando o impacto de prÃ©-processamentos.

## ğŸ“Œ Objetivos
- Realizar **anÃ¡lise exploratÃ³ria de dados (EDA)** para entender os padrÃµes relacionados ao churn.  
- Comparar o desempenho de diferentes modelos de Machine Learning.  
- Explorar os efeitos de **dados sem Smoteen e com Smoteen** nos resultados.  
- Aplicar **tÃ©cnicas de otimizaÃ§Ã£o de hiperparÃ¢metros** (GridSearch).  
- Avaliar os modelos com mÃ©tricas estatÃ­sticas adequadas.  

---

## âš™ï¸ Tecnologias utilizadas
- Python 3.11  
- Pandas, NumPy  
- Matplotlib, Seaborn, Plotly  
- Scikit-learn  
- Statsmodels  
- Joblib  
- Yellowbrick
- Xgboost
- Kaggle
- Imbalanced-learn
- Warning
---

## ğŸ§  Modelos testados  
- **Random Forest Regressor**
- **KNN**
- **GradientBoost**
- **Decision Tree**
- **SVC**
- **Logistic Regressor**
- **Ada Boost**
- **XGBoost**

Com o uso de:
- **GridSearchCV** â†’ Busca dos melhores parÃ¢metros para os modelos
---

## ğŸ“Š MÃ©tricas utilizadas
Para comparar os modelos foram utilizadas mÃ©tricas estatÃ­sticas clÃ¡ssicas de regressÃ£o:

- **MAE (Mean Absolute Error)** â†’ erro mÃ©dio absoluto.  
- **MSE (Mean Squared Error)** â†’ erro quadrÃ¡tico mÃ©dio.  
- **RMSE (Root Mean Squared Error)** â†’ raiz do erro quadrÃ¡tico mÃ©dio.  
- **Accuracy** â†’ PrecisÃ£o do modelo   

AlÃ©m disso, foi utilizada a tÃ©cnica **MultiComparison** (do Statsmodels) para avaliar estatisticamente as diferenÃ§as entre os modelos.

---

## ğŸ“ˆ Principais resultados
- A anÃ¡lise mostrou diferenÃ§as relevantes entre modelos quando lidamos com **dados crus** vs **dados com Smoteen**.  
- O **KNN** apresentou melhores resultados dentre os outros modelo em relaÃ§Ã£o as mÃ©tricas e pelo MultiComparison.  
![Resultados do MultiComparison](graficos_matrizes_tabelas/GrÃ¡ficoDoMultiComparison.png)
- PorÃ©m quando analisados quanto a melhor precisÃ£o o grÃ¡fico gerado mostra outros resultados
![Resultados dos Modelos Testados utilizando RÂ² sem Smoteen](graficos_matrizes_tabelas/AlgoritmosTreinadosComSmoteenETestandoBaseNormal.png)
- O teste foi feito tambÃ©m na base utilizando o resample do Smoteen
![Resultados dos Modelos Testados utilizando RÂ² com Smoteen](graficos_matrizes_tabelas/AlgoritmosTreinadosComSmoteenETestandoBaseSmoteen.png)
- Esses resultados foram gerados por modelos treinados com uma base de treino utilizando o resample do Smoteen pois ela gerou resultados melhores de treino
- do que a base original.
---

## ğŸ“‚ Estrutura do projeto
```
ğŸ“¦ PredicaoDeChurn
 â”£ ğŸ“œ Main.ipynb        # Notebook principal com todo o pipeline
 â”£ ğŸ“œ requirements.txt  # DependÃªncias do projeto
 â”£ ğŸ“œ README.md         # DocumentaÃ§Ã£o do projeto
 â”£ ğŸ“‚ models/           # Modelos salvos do projeto
 â”£ ğŸ“‚ graficos_matrizes_tabelas # GrÃ¡ficos gerados do projeto      
 â”— ğŸ“‚ data/             # Dados utilizados 
```

---

## ğŸ’¾ Salvando modelos
Os melhores modelos foram salvos utilizando **joblib**, permitindo reuso em produÃ§Ã£o.

```python
import joblib

# salvar modelo
joblib.dump(melhor_modelo, "models/modelo")

# carregar modelo
modelo = joblib.load("models/modelo")
```

---

## ğŸš€ Como executar
1. Clone este repositÃ³rio:  
   ```bash
   git clone https://github.com/PedroHenriqueBRO/ChurnPrediction.git
   ou
   git clone git@github.com:PedroHenriqueBRO/ChurnPrediction.git
   cd PredicaoDeChurn
   ```
2. Crie um ambiente virtual e instale as dependÃªncias:  
   ```bash
   pip install -r requirements.txt
   ```
3. Abra o Jupyter Notebook e rode o `Main.ipynb`:  
   ```bash
   jupyter notebook
   ou em outra ferramenta (como o VSCode)
   ```

---

## ğŸ“Œ ConclusÃ£o
Este projeto reforÃ§a prÃ¡ticas fundamentais em **Data Science**:  
- PrÃ©-processamento e tratamento de dados.  
- ComparaÃ§Ã£o estatÃ­stica entre modelos.  
- Escolha de algoritmos baseados em resultados e complexidade.  
- DocumentaÃ§Ã£o e reprodutibilidade.  
